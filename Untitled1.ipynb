{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P6y2sEBUUnB",
        "outputId": "55f2be85-a26d-425d-b400-e6b08f17ef95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab Cell 1 — adjust this path to where your dataset lives on Drive\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/archive\"   # folder\n",
        "LOCAL_ROOT = \"/content/urban_yolo\"\n",
        "\n",
        "import os, shutil\n",
        "print(\"Drive path:\", DRIVE_PATH)\n",
        "print(\"Local root:\", LOCAL_ROOT)\n",
        "\n",
        "# If local folder already exists, remove it\n",
        "if os.path.exists(LOCAL_ROOT):\n",
        "    print(\"Local folder exists — removing to ensure clean copy\")\n",
        "    shutil.rmtree(LOCAL_ROOT)\n",
        "\n",
        "# Decide whether it's a zip or a folder in Drive\n",
        "if os.path.isfile(DRIVE_PATH) and DRIVE_PATH.lower().endswith((\".zip\", \".tar.gz\", \".tgz\")):\n",
        "    print(\"Detected archive file. Copying and will unzip...\")\n",
        "    shutil.copy(DRIVE_PATH, \"/content/\")\n",
        "    archive_name = os.path.basename(DRIVE_PATH)\n",
        "    print(\"Copied archive:\", archive_name)\n",
        "    if archive_name.endswith(\".zip\"):\n",
        "        !unzip -q /content/{archive_name} -d {LOCAL_ROOT}\n",
        "    else:\n",
        "        !tar -xzf /content/{archive_name} -C {LOCAL_ROOT}\n",
        "    print(\"Unpacked archive to\", LOCAL_ROOT)\n",
        "else:\n",
        "    print(\"Assuming DRIVE_PATH is a folder. Copying folder contents...\")\n",
        "    src = DRIVE_PATH\n",
        "    if os.path.exists(src):\n",
        "        shutil.copytree(src, LOCAL_ROOT)   # LOCAL_ROOT doesn’t exist anymore\n",
        "        print(\"Copied folder to\", LOCAL_ROOT)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Drive path not found: {src}\")\n",
        "\n",
        "# final listing\n",
        "print(\"\\nTop-level content:\")\n",
        "!ls -la {LOCAL_ROOT} | head -n 40\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpyCz18cXk7X",
        "outputId": "c5b9e71a-376c-4b4c-a651-b78142011369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive path: /content/drive/MyDrive/archive\n",
            "Local root: /content/urban_yolo\n",
            "Local folder exists — removing to ensure clean copy\n",
            "Assuming DRIVE_PATH is a folder. Copying folder contents...\n",
            "Copied folder to /content/urban_yolo\n",
            "\n",
            "Top-level content:\n",
            "total 48\n",
            "drwx------ 11 root root 4096 Sep 17 21:40 .\n",
            "drwxr-xr-x  1 root root 4096 Sep 18 01:13 ..\n",
            "-rw-------  1 root root  510 Sep 17 20:24 config.yaml\n",
            "drwx------  3 root root 4096 Sep 17 21:40 Damaged concrete structures\n",
            "drwx------  3 root root 4096 Sep 17 21:40 DamagedElectricalPoles\n",
            "drwx------  3 root root 4096 Sep 17 21:40 DamagedRoadSigns\n",
            "drwx------  3 root root 4096 Sep 17 21:40 DeadAnimalsPollution\n",
            "drwx------  3 root root 4096 Sep 17 21:40 FallenTrees\n",
            "drwx------  3 root root 4096 Sep 17 21:40 Garbage\n",
            "drwx------  3 root root 4096 Sep 17 21:40 Graffitti\n",
            "drwx------  3 root root 4096 Sep 17 21:40 IllegalParking\n",
            "drwx------  3 root root 4096 Sep 17 21:40 Potholes and RoadCracks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 1 — flatten folders and make consistent labels\n",
        "import os, shutil, glob, re, sys\n",
        "ROOT = \"/content/urban_yolo\"\n",
        "IMAGES_DIR = os.path.join(ROOT, \"images\")\n",
        "LABELS_DIR = os.path.join(ROOT, \"labels\")\n",
        "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
        "os.makedirs(LABELS_DIR, exist_ok=True)\n",
        "\n",
        "# detect class folders (exclude images/ labels/ urban.yaml config etc.)\n",
        "exclude = {\"images\",\"labels\"}\n",
        "all_entries = sorted([d for d in os.listdir(ROOT) if os.path.isdir(os.path.join(ROOT,d)) and d not in exclude])\n",
        "print(\"Detected class folders (will be used as class names):\")\n",
        "for i,name in enumerate(all_entries):\n",
        "    print(f\"  {i:02d}: {name}\")\n",
        "\n",
        "# create mapping folder_name -> id (deterministic by sorted order)\n",
        "class_names = all_entries.copy()\n",
        "cls_to_id = {name: i for i,name in enumerate(class_names)}\n",
        "print(\"\\nMapping (class -> id):\")\n",
        "print(cls_to_id)\n",
        "\n",
        "# Helper to rewrite label files: assumes each label line: class x_center y_center w h\n",
        "def remap_label_file(src_lbl_path, dst_lbl_path, new_class_id):\n",
        "    try:\n",
        "        with open(src_lbl_path, \"r\") as f:\n",
        "            lines = [l.strip() for l in f if l.strip()]\n",
        "    except FileNotFoundError:\n",
        "        lines = []\n",
        "    out_lines = []\n",
        "    for line in lines:\n",
        "        parts = line.split()\n",
        "        if len(parts) >= 5:\n",
        "            # replace class id only, keep coords\n",
        "            out = \" \".join([str(new_class_id)] + parts[1:5])\n",
        "            out_lines.append(out)\n",
        "        else:\n",
        "            # malformed line: keep as-is but warn\n",
        "            out_lines.append(line)\n",
        "    with open(dst_lbl_path, \"w\") as f:\n",
        "        for L in out_lines:\n",
        "            f.write(L + \"\\n\")\n",
        "\n",
        "# iterate folders and copy images + labels into flat structure\n",
        "copied_images = 0\n",
        "copied_labels = 0\n",
        "no_label_count = 0\n",
        "for cls in class_names:\n",
        "    folder = os.path.join(ROOT, cls)\n",
        "    files = sorted(os.listdir(folder))\n",
        "    for fname in files:\n",
        "        if fname.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "            src_img = os.path.join(folder, fname)\n",
        "            dst_img = os.path.join(IMAGES_DIR, fname)\n",
        "            # ensure unique destination filename (if duplicates exist, prefix with class)\n",
        "            if os.path.exists(dst_img):\n",
        "                base, ext = os.path.splitext(fname)\n",
        "                dst_img = os.path.join(IMAGES_DIR, f\"{cls.replace(' ','')}{base}{ext}\")\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            copied_images += 1\n",
        "\n",
        "            # label handling: look for same-basename .txt in same class folder\n",
        "            base = os.path.splitext(fname)[0]\n",
        "            src_lbl = os.path.join(folder, base + \".txt\")\n",
        "            dst_lbl = os.path.join(LABELS_DIR, os.path.splitext(os.path.basename(dst_img))[0] + \".txt\")\n",
        "            if os.path.exists(src_lbl):\n",
        "                remap_label_file(src_lbl, dst_lbl, cls_to_id[cls])\n",
        "                copied_labels += 1\n",
        "            else:\n",
        "                # create empty label file so YOLO recognizes no objects in that image\n",
        "                open(dst_lbl, \"w\").close()\n",
        "                no_label_count += 1\n",
        "\n",
        "print(f\"\\nDone. Images copied: {copied_images}, labels present and remapped: {copied_labels}, images with NO label (empty .txt): {no_label_count}\")\n",
        "print(\"Images dir:\",IMAGES_DIR)\n",
        "print(\"Labels dir:\",LABELS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn2UJEfLhZG7",
        "outputId": "bcd826b1-b470-4272-9b98-e25ca6b9a84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected class folders (will be used as class names):\n",
            "  00: Damaged concrete structures\n",
            "  01: DamagedElectricalPoles\n",
            "  02: DamagedRoadSigns\n",
            "  03: DeadAnimalsPollution\n",
            "  04: FallenTrees\n",
            "  05: Garbage\n",
            "  06: Graffitti\n",
            "  07: IllegalParking\n",
            "  08: Potholes and RoadCracks\n",
            "\n",
            "Mapping (class -> id):\n",
            "{'Damaged concrete structures': 0, 'DamagedElectricalPoles': 1, 'DamagedRoadSigns': 2, 'DeadAnimalsPollution': 3, 'FallenTrees': 4, 'Garbage': 5, 'Graffitti': 6, 'IllegalParking': 7, 'Potholes and RoadCracks': 8}\n",
            "\n",
            "Done. Images copied: 0, labels present and remapped: 0, images with NO label (empty .txt): 0\n",
            "Images dir: /content/urban_yolo/images\n",
            "Labels dir: /content/urban_yolo/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2 — create urban.yaml from class_names\n",
        "import yaml, os\n",
        "ROOT = \"/content/urban_yolo\"\n",
        "yaml_path = os.path.join(ROOT, \"urban.yaml\")\n",
        "\n",
        "# build names dict with numeric keys (0..n-1)\n",
        "names = {i: name.replace(\" \", \"_\") for i,name in enumerate(class_names)}\n",
        "data_yaml = {\n",
        "    \"path\": ROOT,\n",
        "    \"train\": \"images/train\" if os.path.isdir(os.path.join(ROOT,\"images\",\"train\")) else \"images\",\n",
        "    \"val\": \"images/val\" if os.path.isdir(os.path.join(ROOT,\"images\",\"val\")) else \"images\",\n",
        "    \"test\": \"images/test\" if os.path.isdir(os.path.join(ROOT,\"images\",\"test\")) else \"images\",\n",
        "    \"nc\": len(names),\n",
        "    \"names\": names\n",
        "}\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    yaml.dump(data_yaml, f)\n",
        "print(\"Created\", yaml_path)\n",
        "print(\"nc:\", data_yaml[\"nc\"])\n",
        "print(\"names:\", data_yaml[\"names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy0ZzWlyhq30",
        "outputId": "572b328a-d1ad-413e-e0a0-1f6a69d6bad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created /content/urban_yolo/urban.yaml\n",
            "nc: 9\n",
            "names: {0: 'Damaged_concrete_structures', 1: 'DamagedElectricalPoles', 2: 'DamagedRoadSigns', 3: 'DeadAnimalsPollution', 4: 'FallenTrees', 5: 'Garbage', 6: 'Graffitti', 7: 'IllegalParking', 8: 'Potholes_and_RoadCracks'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 3 — split images/ + labels/ into train/val/test (moves files)\n",
        "import os, random, shutil, glob\n",
        "ROOT = \"/content/urban_yolo\"\n",
        "IMG = os.path.join(ROOT, \"images\")\n",
        "LBL = os.path.join(ROOT, \"labels\")\n",
        "\n",
        "# Only split if images/train doesn't already exist\n",
        "if not os.path.isdir(os.path.join(IMG, \"train\")):\n",
        "    imgs = [f for f in os.listdir(IMG) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
        "    print(\"Total flat images to split:\", len(imgs))\n",
        "    random.seed(42)\n",
        "    random.shuffle(imgs)\n",
        "    n = len(imgs)\n",
        "    t1 = int(0.8*n); t2 = int(0.9*n)\n",
        "    splits = {\"train\": imgs[:t1], \"val\": imgs[t1:t2], \"test\": imgs[t2:]}\n",
        "    for split, files in splits.items():\n",
        "        os.makedirs(os.path.join(IMG, split), exist_ok=True)\n",
        "        os.makedirs(os.path.join(LBL, split), exist_ok=True)\n",
        "        for fname in files:\n",
        "            shutil.move(os.path.join(IMG, fname), os.path.join(IMG, split, fname))\n",
        "            lbl = os.path.splitext(fname)[0] + \".txt\"\n",
        "            src_lbl = os.path.join(LBL, lbl)\n",
        "            dst_lbl = os.path.join(LBL, split, lbl)\n",
        "            if os.path.exists(src_lbl):\n",
        "                shutil.move(src_lbl, dst_lbl)\n",
        "            else:\n",
        "                open(dst_lbl,\"w\").close()\n",
        "    print(\"Split complete. Sizes:\", {k: len(v) for k,v in splits.items()})\n",
        "else:\n",
        "    print(\"images/train already exists — skipping split.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49mT5kEnh1KX",
        "outputId": "e1d9063f-155b-4b17-a804-6f23234c48f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total flat images to split: 0\n",
            "Split complete. Sizes: {'train': 0, 'val': 0, 'test': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 4 — count & inspect\n",
        "import os, glob, json\n",
        "ROOT = \"/content/urban_yolo\"\n",
        "for part in [\"train\",\"val\",\"test\"]:\n",
        "    imgp = os.path.join(ROOT,\"images\",part) if os.path.isdir(os.path.join(ROOT,\"images\",part)) else os.path.join(ROOT,\"images\")\n",
        "    lblp = os.path.join(ROOT,\"labels\",part) if os.path.isdir(os.path.join(ROOT,\"labels\",part)) else os.path.join(ROOT,\"labels\")\n",
        "    imgs = glob.glob(os.path.join(imgp,\".\"))\n",
        "    lbls = glob.glob(os.path.join(lblp,\"*.txt\"))\n",
        "    print(f\"{part.upper():5}: images={len(imgs):5}, labels={len(lbls):5}, img-folder={imgp}\")\n",
        "# print a few sample label files\n",
        "import random\n",
        "sample_lbls = glob.glob(os.path.join(ROOT,\"labels\",\"\",\"*.txt\"), recursive=True)[:10]\n",
        "print(\"\\nSample label files (first 10):\")\n",
        "for s in sample_lbls[:10]:\n",
        "    print(\"==\", s)\n",
        "    print(open(s).read().strip()[:400])\n",
        "    print(\"----\")\n",
        "print(\"\\nIf label lines look like: '2 0.5123 0.412 0.23 0.15' that's good (class x_center y_center w h normalized).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0VYpQhmh_DD",
        "outputId": "eaffed32-86d8-46e6-a63b-e2358d0a6730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: images=    1, labels=    0, img-folder=/content/urban_yolo/images/train\n",
            "VAL  : images=    1, labels=    0, img-folder=/content/urban_yolo/images/val\n",
            "TEST : images=    1, labels=    0, img-folder=/content/urban_yolo/images/test\n",
            "\n",
            "Sample label files (first 10):\n",
            "\n",
            "If label lines look like: '2 0.5123 0.412 0.23 0.15' that's good (class x_center y_center w h normalized).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: delete top-level folders with zero images (run in Colab)\n",
        "import os, shutil\n",
        "\n",
        "ROOT = \"/content/urban_yolo\"\n",
        "img_exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\")\n",
        "removed = []\n",
        "kept = []\n",
        "\n",
        "for entry in sorted(os.listdir(ROOT)):\n",
        "    path = os.path.join(ROOT, entry)\n",
        "    if not os.path.isdir(path):\n",
        "        continue\n",
        "    # count images recursively\n",
        "    img_count = 0\n",
        "    for r, _, files in os.walk(path):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(img_exts):\n",
        "                img_count += 1\n",
        "    if img_count == 0:\n",
        "        try:\n",
        "            shutil.rmtree(path)\n",
        "            removed.append(entry)\n",
        "            print(f\"Removed (no images): {entry}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to remove {entry}: {e}\")\n",
        "    else:\n",
        "        kept.append((entry, img_count))\n",
        "        print(f\"Kept: {entry}  — images: {img_count}\")\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(\"Removed:\", removed)\n",
        "print(\"Kept:\", kept)\n",
        "\n",
        "# final top-level listing\n",
        "print(\"\\nFinal top-level content:\")\n",
        "for name in sorted(os.listdir(ROOT)):\n",
        "    p = os.path.join(ROOT, name)\n",
        "    flag = \"DIR\" if os.path.isdir(p) else \"FILE\"\n",
        "    print(f\"{flag}\\t{name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3muveC4iQQW",
        "outputId": "0b04e490-ade2-474f-d9e4-eb9df319a8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kept: Damaged concrete structures  — images: 9315\n",
            "Kept: DamagedElectricalPoles  — images: 8112\n",
            "Kept: Garbage  — images: 300\n",
            "Kept: Potholes and RoadCracks  — images: 104\n",
            "\n",
            "Summary:\n",
            "Removed: []\n",
            "Kept: [('Damaged concrete structures', 9315), ('DamagedElectricalPoles', 8112), ('Garbage', 300), ('Potholes and RoadCracks', 104)]\n",
            "\n",
            "Final top-level content:\n",
            "DIR\tDamaged concrete structures\n",
            "DIR\tDamagedElectricalPoles\n",
            "DIR\tGarbage\n",
            "DIR\tPotholes and RoadCracks\n",
            "FILE\tconfig.yaml\n",
            "FILE\turban.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 — inspect structure & annotations\n",
        "import os, glob\n",
        "ROOT = \"/content/urban_yolo\"\n",
        "img_exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\")\n",
        "ann_exts = (\".txt\",\".xml\",\".json\")\n",
        "\n",
        "summary = {}\n",
        "for cls in sorted(os.listdir(ROOT)):\n",
        "    p = os.path.join(ROOT, cls)\n",
        "    if not os.path.isdir(p):\n",
        "        continue\n",
        "    summary[cls] = {\"images\":0, \"annotations\":0, \"has_splits\": False, \"split_names\": []}\n",
        "    for root, dirs, files in os.walk(p):\n",
        "        for f in files:\n",
        "            lf = f.lower()\n",
        "            if lf.endswith(img_exts):\n",
        "                summary[cls][\"images\"] += 1\n",
        "            if lf.endswith(ann_exts):\n",
        "                summary[cls][\"annotations\"] += 1\n",
        "        # detect presence of train/val/test folders directly under class\n",
        "        rel = os.path.relpath(root, p)\n",
        "        if rel in (\"train\",\"val\",\"test\"):\n",
        "            if \"has_splits\" in summary[cls]:\n",
        "                summary[cls][\"has_splits\"] = True\n",
        "                summary[cls][\"split_names\"].append(rel)\n",
        "\n",
        "# Print concise report\n",
        "for cls, info in summary.items():\n",
        "    print(f\"{cls:<30} images: {info['images']:6}   anns: {info['annotations']:6}   splits: {info['has_splits']} {info['split_names']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qosRrV1rlVBv",
        "outputId": "1f2d1777-1ebc-4e2c-b675-85df378bd506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Damaged concrete structures    images:   9315   anns:   8554   splits: False []\n",
            "DamagedElectricalPoles         images:   8112   anns:   8112   splits: False []\n",
            "Garbage                        images:    300   anns:      0   splits: False []\n",
            "Potholes and RoadCracks        images:    104   anns:      0   splits: False []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 — reorganize dataset automatically\n",
        "import os, glob, shutil, random\n",
        "random.seed(42)\n",
        "\n",
        "SRC = \"/content/urban_yolo\"\n",
        "YOLO_DST = \"/content/urban_yolo_prepared\"\n",
        "IMGCLS_DST = \"/content/urban_yolo_imageclass\"\n",
        "img_exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\")\n",
        "ann_exts = (\".txt\",\".xml\",\".json\")\n",
        "\n",
        "# helper to ensure dir\n",
        "def mk(d): os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# detect if ANY annotation files exist anywhere\n",
        "any_anns = False\n",
        "for root, _, files in os.walk(SRC):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(ann_exts):\n",
        "            any_anns = True\n",
        "            break\n",
        "    if any_anns: break\n",
        "\n",
        "print(\"Annotations found anywhere?:\", any_anns)\n",
        "\n",
        "if any_anns:\n",
        "    print(\"Preparing YOLO-style dataset at:\", YOLO_DST)\n",
        "    # create structure\n",
        "    for split in (\"train\",\"val\",\"test\"):\n",
        "        mk(os.path.join(YOLO_DST, \"images\", split))\n",
        "        mk(os.path.join(YOLO_DST, \"labels\", split))\n",
        "    # For each class, try to find images; if pre-split exists (train/val/test inside class) keep them, else split 80/10/10\n",
        "    for cls in sorted(os.listdir(SRC)):\n",
        "        cls_path = os.path.join(SRC, cls)\n",
        "        if not os.path.isdir(cls_path): continue\n",
        "        # check if class contains train/val/test\n",
        "        splits_present = [d for d in (\"train\",\"val\",\"test\") if os.path.isdir(os.path.join(cls_path, d))]\n",
        "        if splits_present:\n",
        "            # iterate through each split folder and copy images+anns\n",
        "            for sp in splits_present:\n",
        "                # likely nested under images/ subfolder\n",
        "                img_dirs = []\n",
        "                candidate = os.path.join(cls_path, sp, \"images\")\n",
        "                if os.path.isdir(candidate):\n",
        "                    img_dirs.append(candidate)\n",
        "                else:\n",
        "                    img_dirs.append(os.path.join(cls_path, sp))\n",
        "                for idir in img_dirs:\n",
        "                    if not os.path.isdir(idir): continue\n",
        "                    for f in os.listdir(idir):\n",
        "                        if f.lower().endswith(img_exts):\n",
        "                            src_img = os.path.join(idir, f)\n",
        "                            shutil.copy(src_img, os.path.join(YOLO_DST, \"images\", sp, f))\n",
        "                            # try copy matching annotations by basename\n",
        "                            base = os.path.splitext(f)[0]\n",
        "                            for aext in ann_exts:\n",
        "                                src_ann = os.path.join(os.path.dirname(idir), \"labels\", base + aext)\n",
        "                                if os.path.exists(src_ann):\n",
        "                                    shutil.copy(src_ann, os.path.join(YOLO_DST, \"labels\", sp, base + aext))\n",
        "                                else:\n",
        "                                    # check same folder as images\n",
        "                                    src_ann2 = os.path.join(idir, base + aext)\n",
        "                                    if os.path.exists(src_ann2):\n",
        "                                        shutil.copy(src_ann2, os.path.join(YOLO_DST, \"labels\", sp, base + aext))\n",
        "        else:\n",
        "            # no pre-splits: gather all images and split 80/10/10\n",
        "            imgs = []\n",
        "            for root, _, files in os.walk(cls_path):\n",
        "                for f in files:\n",
        "                    if f.lower().endswith(img_exts):\n",
        "                        imgs.append(os.path.join(root, f))\n",
        "            if not imgs:\n",
        "                continue\n",
        "            random.shuffle(imgs)\n",
        "            n = len(imgs)\n",
        "            n_train = int(n*0.8)\n",
        "            n_val = int(n*0.1)\n",
        "            train_imgs = imgs[:n_train]\n",
        "            val_imgs = imgs[n_train:n_train+n_val]\n",
        "            test_imgs = imgs[n_train+n_val:]\n",
        "            for sp, group in [(\"train\", train_imgs), (\"val\", val_imgs), (\"test\", test_imgs)]:\n",
        "                for src_img in group:\n",
        "                    fname = os.path.basename(src_img)\n",
        "                    shutil.copy(src_img, os.path.join(YOLO_DST, \"images\", sp, fname))\n",
        "                    base = os.path.splitext(fname)[0]\n",
        "                    # try to find annotation file near the image\n",
        "                    found_ann = False\n",
        "                    for aext in ann_exts:\n",
        "                        cand = os.path.join(os.path.dirname(src_img), base + aext)\n",
        "                        if os.path.exists(cand):\n",
        "                            shutil.copy(cand, os.path.join(YOLO_DST, \"labels\", sp, base + aext))\n",
        "                            found_ann = True\n",
        "                            break\n",
        "    print(\"YOLO-style dataset prepared. Preview counts:\")\n",
        "    for sp in (\"train\",\"val\",\"test\"):\n",
        "        imgs = len(list(glob.glob(os.path.join(YOLO_DST,\"images\",sp,\"*\"))))\n",
        "        anns = len(list(glob.glob(os.path.join(YOLO_DST,\"labels\",sp,\"*\"))))\n",
        "        print(f\"{sp}: images={imgs}, annotations={anns}\")\n",
        "\n",
        "else:\n",
        "    print(\"No annotations found — preparing ImageFolder classification dataset at:\", IMGCLS_DST)\n",
        "    for split in (\"train\",\"val\",\"test\"):\n",
        "        for cls in sorted(os.listdir(SRC)):\n",
        "            cls_path = os.path.join(SRC, cls)\n",
        "            if not os.path.isdir(cls_path): continue\n",
        "            # gather images recursively\n",
        "            imgs = []\n",
        "            for root, _, files in os.walk(cls_path):\n",
        "                for f in files:\n",
        "                    if f.lower().endswith(img_exts):\n",
        "                        imgs.append(os.path.join(root, f))\n",
        "            if not imgs:\n",
        "                continue\n",
        "            random.shuffle(imgs)\n",
        "            n = len(imgs)\n",
        "            n_train = int(n*0.8)\n",
        "            n_val = int(n*0.1)\n",
        "            train_imgs = imgs[:n_train]\n",
        "            val_imgs = imgs[n_train:n_train+n_val]\n",
        "            test_imgs = imgs[n_train+n_val:]\n",
        "            groups = {\"train\":train_imgs,\"val\":val_imgs,\"test\":test_imgs}\n",
        "            out_dir = os.path.join(IMGCLS_DST, split, cls)\n",
        "            os.makedirs(out_dir, exist_ok=True)\n",
        "            for sp, group in groups.items():\n",
        "                out_dir_sp = os.path.join(IMGCLS_DST, sp, cls)\n",
        "                os.makedirs(out_dir_sp, exist_ok=True)\n",
        "                for src_img in group:\n",
        "                    shutil.copy(src_img, os.path.join(out_dir_sp, os.path.basename(src_img)))\n",
        "    # print counts\n",
        "    for split in (\"train\",\"val\",\"test\"):\n",
        "        tot = sum(len(files) for _,_,files in os.walk(os.path.join(IMGCLS_DST,split)))\n",
        "        print(f\"{split}: total images = {tot}\")\n",
        "\n",
        "print(\"Done. Check the new folder(s) and tell me which format you prefer to train with.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adatHU7yln9K",
        "outputId": "cf14f401-00f7-442b-8e77-14e6e40a4b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations found anywhere?: True\n",
            "Preparing YOLO-style dataset at: /content/urban_yolo_prepared\n",
            "YOLO-style dataset prepared. Preview counts:\n",
            "train: images=14264, annotations=0\n",
            "val: images=1782, annotations=0\n",
            "test: images=1785, annotations=0\n",
            "Done. Check the new folder(s) and tell me which format you prefer to train with.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 — generate dataset.yaml for YOLO (run if /content/urban_yolo_prepared exists)\n",
        "import os, yaml, glob\n",
        "PREP = \"/content/urban_yolo_prepared\"\n",
        "if not os.path.isdir(PREP):\n",
        "    print(\"YOLO prepared folder not found:\", PREP)\n",
        "else:\n",
        "    # gather classes by scanning train images parent class names — we can't infer class names directly from images,\n",
        "    # so we'll read class names from the original SRC top-level folders that were kept (best-effort)\n",
        "    SRC = \"/content/urban_yolo\"\n",
        "    classes = [d for d in sorted(os.listdir(SRC)) if os.path.isdir(os.path.join(SRC,d))]\n",
        "    nc = len(classes)\n",
        "    data = {\n",
        "        \"train\": os.path.join(PREP, \"images\", \"train\"),\n",
        "        \"val\":   os.path.join(PREP, \"images\", \"val\"),\n",
        "        \"test\":  os.path.join(PREP, \"images\", \"test\"),\n",
        "        \"nc\": nc,\n",
        "        \"names\": classes\n",
        "    }\n",
        "    yaml_path = \"/content/urban_yolo_prepared/dataset.yaml\"\n",
        "    with open(yaml_path, \"w\") as f:\n",
        "        yaml.dump(data, f)\n",
        "    print(\"Wrote dataset.yaml ->\", yaml_path)\n",
        "    print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT4eaiVEl_C7",
        "outputId": "8272e895-8a82-4009-cc16-12dfcc190831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote dataset.yaml -> /content/urban_yolo_prepared/dataset.yaml\n",
            "{'train': '/content/urban_yolo_prepared/images/train', 'val': '/content/urban_yolo_prepared/images/val', 'test': '/content/urban_yolo_prepared/images/test', 'nc': 4, 'names': ['Damaged concrete structures', 'DamagedElectricalPoles', 'Garbage', 'Potholes and RoadCracks']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run in a Colab cell (bash)\n",
        "!pip install -q ultralytics\n",
        "!yolo detect train data=/content/urban_yolo_prepared/dataset.yaml model=yolov8n.pt epochs=25 imgsz=640\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggjwREzfmGgP",
        "outputId": "00fcae02-bfaf-44c6-e290-8847e62e9266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 66.1MB/s 0.1s\n",
            "Ultralytics 8.3.201 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (AMD EPYC 7B12)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/urban_yolo_prepared/dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=25, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 12.4MB/s 0.1s\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 927.8±1015.1 MB/s, size: 83.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/urban_yolo_prepared/labels/train... 0 images, 14264 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 14264/14264 715.8it/s 19.9s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/urban_yolo_prepared/images/train/Datacluster Trash (236).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/urban_yolo_prepared/images/train/Datacluster Trash (240).jpg: corrupt JPEG restored and saved\n",
            "WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in /content/urban_yolo_prepared/labels/train.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/urban_yolo_prepared/labels/train.cache\n",
            "WARNING ⚠️ Labels are missing or empty in /content/urban_yolo_prepared/labels/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 557.7±574.3 MB/s, size: 102.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/urban_yolo_prepared/labels/val... 0 images, 1782 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1782/1782 638.9it/s 2.8s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/urban_yolo_prepared/images/val/Datacluster Trash (237).jpg: corrupt JPEG restored and saved\n",
            "WARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mNo labels found in /content/urban_yolo_prepared/labels/val.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/urban_yolo_prepared/labels/val.cache\n",
            "WARNING ⚠️ Labels are missing or empty in /content/urban_yolo_prepared/labels/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "WARNING ⚠️ zero-size array to reduction operation maximum which has no identity\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/25         0G          0      60.36          0          0        640: 100% ━━━━━━━━━━━━ 892/892 0.1it/s 2:25:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 56/56 0.1it/s 6:54\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "                   all       1782          0          0          0          0          0\n",
            "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/25         0G          0      2.165          0          0        640: 77% ━━━━━━━━━─── 691/892 0.1it/s 1:49:51<29:40"
          ]
        }
      ]
    }
  ]
}